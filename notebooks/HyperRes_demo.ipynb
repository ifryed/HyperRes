{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E0mhoAYa0GAV"
      },
      "source": [
        "# HyperRes: Hypernetwork-Based Adaptive Image Restoration\n",
        "# Live Demo\n",
        "\n",
        "### Instructions:\n",
        "Run all the cells (Clone Git, Imports..)\n",
        "\n",
        "If you want to upload your own image use the \"Upload images\" cell and re-run the \"Choose Image\" cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKCuMa7U-pg4",
        "outputId": "0a83cbab-1f7d-40b5-aa2e-2e113a062e6d"
      },
      "outputs": [],
      "source": [
        "#@title Clone Git\n",
        "import os\n",
        "! git clone https://github.com/ifryed/HyperRes.git\n",
        "\n",
        "curr_workdir = f'./HyperRes'\n",
        "if os.path.exists(curr_workdir):\n",
        "  os.chdir(curr_workdir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "9bhiA6To9hjz"
      },
      "outputs": [],
      "source": [
        "#@title Imports\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "\n",
        "from models import HyperRes, NoiseNet\n",
        "from utils.DataUtils.CommonTools import modcrop, ToTensor, calculate_psnr, postProcessForStats\n",
        "\n",
        "img_fld = 'notebooks/demo_imgs'\n",
        "os.makedirs(img_fld, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WAMM5iZc94GS"
      },
      "outputs": [],
      "source": [
        "#@title Corruption fuctions\n",
        "#@markdown - Gaussian Noise\n",
        "#@markdown - Super Resulution\n",
        "#@markdown - JPEG \n",
        "\n",
        "def addNoise(src1, noise=None):\n",
        "    global title_window\n",
        "    sig = np.random.randint(0, 100)\n",
        "\n",
        "    if noise:\n",
        "        sig = noise\n",
        "    title_window = \"Noise Sigma {}\".format(sig)\n",
        "    ret_img = src1 + np.random.normal(0, sig / 255, src1.shape)\n",
        "    return np.clip(ret_img, 0, 1), sig\n",
        "\n",
        "\n",
        "def addSR(src1, lvl=None):\n",
        "    global title_window\n",
        "\n",
        "    if not lvl:\n",
        "        lvl = np.random.randint(2, 6)\n",
        "    title_window = \"SR Factor {}\".format(lvl)\n",
        "    ret_img = cv2.resize(src1, (0, 0), fx=1 / lvl, fy=1 / lvl, interpolation=cv2.INTER_CUBIC)\n",
        "    ret_img = cv2.resize(ret_img, tuple(src1.shape[-2::-1]), interpolation=cv2.INTER_CUBIC)\n",
        "    return np.clip(ret_img, 0, 1), lvl * 10\n",
        "\n",
        "\n",
        "def addDeJPEG(src1, lvl=None):\n",
        "    global title_window\n",
        "\n",
        "    if not lvl:\n",
        "        lvl = np.random.randint(10, 100)\n",
        "    title_window = \"SR Factor {}\".format(lvl)\n",
        "    cv2.imwrite('tmp.jpg', src1 * 255, [int(cv2.IMWRITE_JPEG_QUALITY), lvl])\n",
        "    ret_img = cv2.imread('tmp.jpg') / 255\n",
        "    os.remove('tmp.jpg')\n",
        "    return np.clip(ret_img, 0, 1), lvl\n",
        "\n",
        "curr_dict = {\"SuperResolution\": addSR, \"GaussianNoise\": addNoise, \"JPEG\": addDeJPEG}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PDHu_5X--JWd"
      },
      "outputs": [],
      "source": [
        "#@title Model Loading Functions\n",
        "\n",
        "def loadNoiseNet(device):\n",
        "  model_weights = 'pre_trained/noise_detect.pth'\n",
        "  noise_model = NoiseNet().to(device)\n",
        "  noise_model.load_state_dict(torch.load(model_weights, map_location=device), strict=False)\n",
        "  return noise_model\n",
        "\n",
        "def loadHyperResNet(model_weights, data_type,device):\n",
        "  if not model_weights or not os.path.exists(model_weights):\n",
        "    print(\"Could not find the weights\")\n",
        "    return None\n",
        "  checkpoint = torch.load(model_weights, map_location=device)\n",
        "  model = HyperRes(meta_blocks=16,\n",
        "                     level=[0], device=device,\n",
        "                     gray=False).to(device)\n",
        "  model.load_state_dict(checkpoint['state_dict'])\n",
        "  return model\n",
        "\n",
        "model_dict = {\n",
        "    \"SuperResolution\": 'pre_trained/sr_4.pth',\n",
        "    \"GaussianNoise\": 'pre_trained/noise_4.pth',\n",
        "    \"JPEG\": 'pre_trained/jpeg_4_color.pth',}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "bZS76vINSpM3",
        "outputId": "e0bd237f-c7a9-410f-a7b1-4bce7f43f4b4"
      },
      "outputs": [],
      "source": [
        "#@title Upload images\n",
        "#@markdown Only if you don't like the pre-loaded images!",
        "\n",
        "uploaded = files.upload()\n",
        "file_path = list(uploaded.keys())[0]\n",
        "os.rename(file_path,os.path.join(img_fld,file_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626,
          "referenced_widgets": [
            "d11839fe791344588e607d6203be9415",
            "96c22ca51a854089ab56fa28f62e5bb7",
            "e7a394f3a74547439dc918a10d9a6b26"
          ]
        },
        "id": "kq2_728UGa_E",
        "outputId": "1f11554e-1959-4c73-975e-41c2078d170e"
      },
      "outputs": [],
      "source": [
        "#@title Choose Image { run: \"auto\" }\n",
        "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "img_lst = os.listdir(img_fld)\n",
        "\n",
        "Dropdown_ = widgets.Dropdown(\n",
        "    options=img_lst,\n",
        "    description='Image',\n",
        ")\n",
        "output = widgets.Output()\n",
        "\n",
        "def on_change(change):\n",
        "  global gt\n",
        "  plt.rcParams["figure.figsize"] = (10,10)",
        "  gt = cv2.imread(os.path.join(img_fld,change['new']))\n",
        "  plt.imshow(gt[:,:,::-1])\n",
        "\n",
        "def on_display(change):\n",
        "  global gt\n",
        "  plt.rcParams["figure.figsize"] = (10,10)",
        "  gt = cv2.imread(os.path.join(img_fld,change.options[0]))\n",
        "  plt.imshow(gt[:,:,::-1])\n",
        "\n",
        "Dropdown_.observe(on_change, names='value')\n",
        "Dropdown_.on_displayed(on_display)\n",
        "display(Dropdown_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "QDjmqo5RBJJl",
        "outputId": "fcfc9f77-8132-4dbc-abe9-032819017b41"
      },
      "outputs": [],
      "source": [
        "#@title Select Corruption level { run: \"auto\" }\n",
        "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "global gt\n",
        "device = torch.device(\"cpu\") if not torch.cuda.is_available() else torch.device(\"cuda:0\")\n",
        "\n",
        "Corruption = \"GaussianNoise\" #@param [\"GaussianNoise\",\"SuperResolution\",\"JPEG\"]\n",
        "\n",
        "noise_level = 50 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "jpeg_level = 50 #@param {type:\"slider\", min:1, max:100, step:-1}\n",
        "sr_level = 3 #@param {type:\"slider\", min:1, max:10, step:0.1}\n",
        "\n",
        "corr_lvl_dict = {\n",
        "    \"SuperResolution\": sr_level,\n",
        "    \"GaussianNoise\": noise_level,\n",
        "    \"JPEG\": jpeg_level}\n",
        "corrupt_fun = curr_dict[Corruption]\n",
        "\n",
        "gt_c = gt[:,:,:]\n",
        "\n",
        "src1, rnd_noise = corrupt_fun(gt / 255, corr_lvl_dict[Corruption])\n",
        "src_t = ToTensor()(src1).to(device).unsqueeze(0)\n",
        "\n",
        "plt.imshow(src1[:,:,::-1],cmap='gray')\n",
        "noise_net = loadNoiseNet(device)\n",
        "model = loadHyperResNet(model_dict[Corruption],Corruption,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528
        },
        "id": "MwcExp1ZNzYw",
        "outputId": "340e9761-0cfd-48be-f5bc-84dc283b09c7"
      },
      "outputs": [],
      "source": [
        "plt.rcParams[\"figure.figsize\"] = (30,70)\n",
        "#@title Restoration Level Slider { run: \"auto\" }\n",
        "correction_level = 3 #@param {type:\"slider\", min:0, max:100, step:1}\n",
        "correction_level_sr = 1.3 #@param {type:\"slider\", min:0, max:6, step:0.1}\n",
        "if Corruption == 'SuperResolution':\n",
        "  model.setLevel(correction_level_sr)\n",
        "else:\n",
        "  model.setLevel(correction_level)\n",
        "\n",
        "with torch.no_grad():\n",
        "  dst = model([src_t])[0]\n",
        "dst = postProcessForStats(dst)[0]\n",
        "\n",
        "plt.subplot(1,3,1)\n",
        "plt.title('GT')\n",
        "_ = plt.imshow(gt[:,:,::-1])\n",
        "\n",
        "plt.subplot(1,3,2)\n",
        "plt.title('Corrupt')\n",
        "_ = plt.imshow(src1[:,:,::-1])\n",
        "\n",
        "plt.subplot(1,3,3)\n",
        "plt.title('Restored $\\sigma$={}'.format(correction_level))\n",
        "_ = plt.imshow(dst[:,:,::-1])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "pa_shai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "vscode": {
      "interpreter": {
        "hash": "be5100903ab2843f1fd35058a99daa838d84398120321e6418ff1326b788bdd0"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "96c22ca51a854089ab56fa28f62e5bb7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d11839fe791344588e607d6203be9415": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DropdownModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DropdownModel",
            "_options_labels": [
              "Screenshot_20230125_221854.png"
            ],
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "DropdownView",
            "description": "Image",
            "description_tooltip": null,
            "disabled": false,
            "index": 0,
            "layout": "IPY_MODEL_96c22ca51a854089ab56fa28f62e5bb7",
            "style": "IPY_MODEL_e7a394f3a74547439dc918a10d9a6b26"
          }
        },
        "e7a394f3a74547439dc918a10d9a6b26": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
